{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: pyarrow>=10.0.1 is required for PyArrow backed StringArray.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\backends.py:140\u001b[39m, in \u001b[36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:5374\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, columns, filters, categories, index, storage_options, dtype_backend, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, blocksize, aggregate_files, parquet_file_extension, filesystem, engine, arrow_to_pandas, **kwargs)\u001b[39m\n\u001b[32m   5355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\n\u001b[32m   5356\u001b[39m         ReadParquetPyarrowFS(\n\u001b[32m   5357\u001b[39m             path,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5370\u001b[39m         )\n\u001b[32m   5371\u001b[39m     )\n\u001b[32m   5373\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\n\u001b[32m-> \u001b[39m\u001b[32m5374\u001b[39m     \u001b[43mReadParquetFSSpec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_convert_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcalculate_divisions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcalculate_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5384\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5386\u001b[39m \u001b[43m        \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparquet_file_extension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparquet_file_extension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_set_parquet_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5391\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_series\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5392\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5393\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\_expr.py:875\u001b[39m, in \u001b[36mSingletonExpr.__new__\u001b[39m\u001b[34m(cls, _determ_token, *args, **kwargs)\u001b[39m\n\u001b[32m    874\u001b[39m     \u001b[38;5;28mcls\u001b[39m._instances = weakref.WeakValueDictionary()\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m inst = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_determ_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_determ_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m _name = inst._name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\_expr.py:72\u001b[39m, in \u001b[36mExpr.__new__\u001b[39m\u001b[34m(cls, _determ_token, *args, **kwargs)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# This is typically cached. Make sure the cache is populated by calling\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# it once\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inst\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\functools.py:1001\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\io\\parquet.py:790\u001b[39m, in \u001b[36mReadParquet._name\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._funcname + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeterministic_token\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\_expr.py:538\u001b[39m, in \u001b[36mExpr.deterministic_token\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token:\n\u001b[32m    536\u001b[39m     \u001b[38;5;66;03m# Just tokenize self to fall back on __dask_tokenize__\u001b[39;00m\n\u001b[32m    537\u001b[39m     \u001b[38;5;66;03m# Note how this differs to the implementation of __dask_tokenize__\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m     \u001b[38;5;28mself\u001b[39m._determ_token = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__dask_tokenize__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\io\\parquet.py:784\u001b[39m, in \u001b[36mReadParquet.__dask_tokenize__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# TODO: Is there an actual need to overwrite this?\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;28mself\u001b[39m._determ_token = _tokenize_deterministic(\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m         funcname(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchecksum\u001b[49m, *\u001b[38;5;28mself\u001b[39m.operands[:-\u001b[32m1\u001b[39m]\n\u001b[32m    785\u001b[39m     )\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._determ_token\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\io\\parquet.py:794\u001b[39m, in \u001b[36mReadParquet.checksum\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchecksum\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_info\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mchecksum\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\io\\parquet.py:1398\u001b[39m, in \u001b[36mReadParquetFSSpec._dataset_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1397\u001b[39m \u001b[38;5;66;03m# Infer meta, accounting for index and columns arguments.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m meta = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_dd_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1399\u001b[39m index = dataset_info[\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:1146\u001b[39m, in \u001b[36mArrowDatasetEngine._create_dd_meta\u001b[39m\u001b[34m(cls, dataset_info)\u001b[39m\n\u001b[32m   1145\u001b[39m dtype_backend = dataset_info[\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1146\u001b[39m meta = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arrow_table_to_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43marrow_to_pandas\u001b[49m\u001b[43m=\u001b[49m\u001b[43marrow_to_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1153\u001b[39m index_names = \u001b[38;5;28mlist\u001b[39m(meta.index.names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:1800\u001b[39m, in \u001b[36mArrowDatasetEngine._arrow_table_to_pandas\u001b[39m\u001b[34m(cls, arrow_table, categories, dtype_backend, convert_string, **kwargs)\u001b[39m\n\u001b[32m   1798\u001b[39m _kwargs.update({\u001b[33m\"\u001b[39m\u001b[33muse_threads\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mignore_metadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m})\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m types_mapper = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_determine_type_mapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m types_mapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:1759\u001b[39m, in \u001b[36mArrowDatasetEngine._determine_type_mapper\u001b[39m\u001b[34m(cls, dtype_backend, convert_string, **kwargs)\u001b[39m\n\u001b[32m   1758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_string:\n\u001b[32m-> \u001b[39m\u001b[32m1759\u001b[39m     type_mappers.append({pa.string(): \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mStringDtype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m}.get)\n\u001b[32m   1760\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m PANDAS_GE_220:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\pandas\\core\\arrays\\string_.py:178\u001b[39m, in \u001b[36mStringDtype.__init__\u001b[39m\u001b[34m(self, storage, na_value)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m storage == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pa_version_under10p1:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    179\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow>=10.0.1 is required for PyArrow backed StringArray.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m     )\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(na_value, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np.isnan(na_value):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# when passed a NaN value, always set to np.nan to ensure we use\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# a consistent NaN value (and we can use `dtype.na_value is np.nan`)\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: pyarrow>=10.0.1 is required for PyArrow backed StringArray.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sorted_results[:top_k]\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# ----------- Run Similarity Search -----------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m top_matches = \u001b[43mfind_best_airfoils_dask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# ----------- Display Results -----------\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(top_matches, \u001b[32m1\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mfind_best_airfoils_dask\u001b[39m\u001b[34m(targets, weights, top_k)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_best_airfoils_dask\u001b[39m(targets, weights, top_k=\u001b[32m3\u001b[39m):\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Load Parquet using Dask\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     df = \u001b[43mdd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     features = \u001b[38;5;28mlist\u001b[39m(targets.keys())\n\u001b[32m     40\u001b[39m     weights_array = np.array([weights[f] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Muhamemd Emin ONAY\\Documents\\aerofil_yz\\forgefoil\\forgefoil\\.conda\\Lib\\site-packages\\dask\\backends.py:151\u001b[39m, in \u001b[36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: pyarrow>=10.0.1 is required for PyArrow backed StringArray."
     ]
    }
   ],
   "source": [
    "# Airfoil Similarity Search with Dask\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ----------- Configuration -----------\n",
    "\n",
    "DATA_PATH = './airfoil_data.parquet'  # Change path if needed\n",
    "\n",
    "# ----------- Sample Payload -----------\n",
    "\n",
    "targets = {\n",
    "    \"cl\": 0.8,\n",
    "    \"cd\": 0.012,\n",
    "    \"cm\": -0.05,\n",
    "    \"reynolds_number\": 1000000,\n",
    "    \"angle_of_attack\": 5,\n",
    "    \"cl_cd_ratio\": 66.7\n",
    "}\n",
    "\n",
    "weights = {\n",
    "    \"cl\": 0.1923076923076923,\n",
    "    \"cd\": 0.1923076923076923,\n",
    "    \"cm\": 0.11538461538461538,\n",
    "    \"reynolds_number\": 0.15384615384615385,\n",
    "    \"angle_of_attack\": 0.17307692307692307,\n",
    "    \"cl_cd_ratio\": 0.17307692307692307\n",
    "}\n",
    "\n",
    "# ----------- Similarity Function -----------\n",
    "\n",
    "def find_best_airfoils_dask(targets, weights, top_k=3):\n",
    "    # Load Parquet using Dask\n",
    "    df = dd.read_parquet(DATA_PATH)\n",
    "\n",
    "    features = list(targets.keys())\n",
    "    weights_array = np.array([weights[f] for f in features])\n",
    "\n",
    "    def compute_similarity(row):\n",
    "        try:\n",
    "            diffs = np.array([row[f] - targets[f] for f in features])\n",
    "            weighted_diffs = weights_array * diffs\n",
    "            similarity_score = np.sum(weighted_diffs ** 2)\n",
    "\n",
    "            feature_scores = {f: row[f] - targets[f] for f in features}\n",
    "\n",
    "            return {\n",
    "                \"airfoil_name\": row.get(\"airfoil_name\", \"\"),\n",
    "                \"airfoil_file\": row.get(\"airfoil_file\", \"\"),\n",
    "                \"reynolds_number\": row[\"reynolds_number\"],\n",
    "                \"angle_of_attack\": row[\"angle_of_attack\"],\n",
    "                \"cl\": row[\"cl\"],\n",
    "                \"cd\": row[\"cd\"],\n",
    "                \"cm\": row[\"cm\"],\n",
    "                \"cl_cd_ratio\": row[\"cl_cd_ratio\"],\n",
    "                \"geometry\": json.loads(row[\"geometry\"]) if isinstance(row.get(\"geometry\"), str) else [],\n",
    "                \"airfoil_id\": row.get(\"airfoil_id\", \"\"),\n",
    "                \"similarity_score\": similarity_score,\n",
    "                \"feature_scores\": feature_scores\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error in row: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Apply row-wise similarity calculation\n",
    "    results = df.map_partitions(lambda partition: partition.apply(compute_similarity, axis=1)).compute()\n",
    "\n",
    "    # Remove failed rows\n",
    "    results = [r for r in results if r is not None]\n",
    "\n",
    "    # Sort and return top-k\n",
    "    sorted_results = sorted(results, key=lambda x: x[\"similarity_score\"])\n",
    "    return sorted_results[:top_k]\n",
    "\n",
    "# ----------- Run Similarity Search -----------\n",
    "\n",
    "top_matches = find_best_airfoils_dask(targets, weights, top_k=3)\n",
    "\n",
    "# ----------- Display Results -----------\n",
    "\n",
    "for i, match in enumerate(top_matches, 1):\n",
    "    print(f\"\\nMatch #{i}\")\n",
    "    print(f\"Airfoil: {match['airfoil_name']}\")\n",
    "    print(f\"Similarity Score: {match['similarity_score']:.6e}\")\n",
    "    print(\"Feature Deltas:\")\n",
    "    for k, v in match['feature_scores'].items():\n",
    "        print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/25.8 MB 4.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.6/25.8 MB 4.0 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.1/25.8 MB 3.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 3.1/25.8 MB 3.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.9/25.8 MB 4.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.5/25.8 MB 3.8 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.2/25.8 MB 3.7 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.3/25.8 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.1/25.8 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.9/25.8 MB 3.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.4/25.8 MB 3.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 9.4/25.8 MB 3.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 10.0/25.8 MB 3.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.7/25.8 MB 3.7 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 11.5/25.8 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.3/25.8 MB 3.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 13.1/25.8 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.9/25.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.7/25.8 MB 3.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 15.5/25.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.3/25.8 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 17.3/25.8 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.8/25.8 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 18.4/25.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.9/25.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.4/25.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.2/25.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 20.4/25.8 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.0/25.8 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.8/25.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.3/25.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.3/25.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 23.1/25.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.6/25.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.1/25.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.4/25.8 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.9/25.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.7/25.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.8/25.8 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
